{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 1\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-k*x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x)*(1.0-sigmoid(x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return 1.0 - x**2\n",
    "\n",
    "def linear(x):\n",
    "    return x\n",
    "\n",
    "def linear_prime(x):\n",
    "    return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.1477724   0.71289253 -0.71579561]\n",
      " [ 0.82069396  0.3461268   0.55155054]\n",
      " [-0.48218343  0.82216793 -0.04233788]]\n",
      "[[-0.11092745]\n",
      " [-0.36767989]\n",
      " [ 0.96344469]]\n",
      "[0 0] [-0.66446589]\n",
      "[0 1] [-0.71126703]\n",
      "[1 0] [-0.47046795]\n",
      "[1 1] [-0.51399121]\n",
      "epochs: 0\n",
      "epochs: 10000\n",
      "epochs: 20000\n",
      "epochs: 30000\n",
      "epochs: 40000\n",
      "epochs: 50000\n",
      "epochs: 60000\n",
      "epochs: 70000\n",
      "epochs: 80000\n",
      "epochs: 90000\n",
      "[0 0] [-5.00905119e-05]\n",
      "[0 1] [0.99557671]\n",
      "[1 0] [0.99660054]\n",
      "[1 1] [9.78728626e-05]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        self.activation = tanh\n",
    "        self.activation_prime = tanh_prime\n",
    "#         self.activation = linear\n",
    "#         self.activation_prime = linear_prime\n",
    "#         self.activation = sigmoid\n",
    "#         self.activation_prime = sigmoid_prime\n",
    "        \n",
    "        # Set weights\n",
    "        self.weights = []\n",
    "        # layers = [2,2,1]\n",
    "        # range of weight values (-1,1)\n",
    "        # input and hidden layers - random((2+1, 2+1)) : 3 x 3\n",
    "        \n",
    "        for i in range(1, len(layers) - 1):\n",
    "            r = 2*np.random.random((layers[i-1] + 1, layers[i] + 1)) -1\n",
    "            self.weights.append(r)\n",
    "            print(r)\n",
    "        # output layer - random((2+1, 1)) : 3 x 1\n",
    "        r = 2*np.random.random( (layers[i] + 1, layers[i+1])) - 1\n",
    "        print(r)\n",
    "        self.weights.append(r)\n",
    "\n",
    "    def fit(self, X, y, learning_rate=0.2, epochs=100000):\n",
    "        # Add column of ones to X\n",
    "        # This is to add the bias unit to the input layer\n",
    "        ones = np.atleast_2d(np.ones(X.shape[0]))\n",
    "        X = np.concatenate((ones.T, X), axis=1)\n",
    "         \n",
    "        for k in range(epochs):\n",
    "            i = np.random.randint(X.shape[0])\n",
    "            a = [X[i]]\n",
    "\n",
    "            for l in range(len(self.weights)):\n",
    "                    dot_value = np.dot(a[l], self.weights[l])\n",
    "                    activation = self.activation(dot_value)\n",
    "                    a.append(activation)\n",
    "            # output layer\n",
    "            error = y[i] - a[-1]\n",
    "            deltas = [error * self.activation_prime(a[-1])]\n",
    "\n",
    "            # we need to begin at the second to last layer \n",
    "            # (a layer before the output layer)\n",
    "            for l in range(len(a) - 2, 0, -1): \n",
    "                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_prime(a[l]))\n",
    "\n",
    "            # reverse\n",
    "            # [level3(output)->level2(hidden)]  => [level2(hidden)->level3(output)]\n",
    "            deltas.reverse()\n",
    "\n",
    "            # backpropagation\n",
    "            # 1. Multiply its output delta and input activation \n",
    "            #    to get the gradient of the weight.\n",
    "            # 2. Subtract a ratio (percentage) of the gradient from the weight.\n",
    "            for i in range(len(self.weights)):\n",
    "                layer = np.atleast_2d(a[i])\n",
    "                delta = np.atleast_2d(deltas[i])\n",
    "                self.weights[i] += learning_rate * layer.T.dot(delta)\n",
    "\n",
    "            if k % 10000 == 0: \n",
    "                print('epochs:', k)\n",
    "\n",
    "    def predict(self, x): \n",
    "    \n",
    "        a = np.concatenate((np.ones(1).T, np.array(x)))      \n",
    "\n",
    "        for l in range(0, len(self.weights)):\n",
    "            a = self.activation(np.dot(a, self.weights[l]))\n",
    "        return a\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    nn = NeuralNetwork([2,2,1])\n",
    "    X = np.array([[0, 0],\n",
    "                  [0, 1],\n",
    "                  [1, 0],\n",
    "                  [1, 1]])\n",
    "    y = np.array([0, 1, 1, 0])\n",
    "#     X = np.array([[-1, -1],\n",
    "#                   [-1, 1],\n",
    "#                   [1, -1],\n",
    "#                   [1, 1]])\n",
    "#     y = np.array([0, 1, 1, 0])\n",
    "    for e in X:\n",
    "        print(e,nn.predict(e))\n",
    "    nn.fit(X, y)\n",
    "    for e in X:\n",
    "        print(e,nn.predict(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.71915045 -0.1588788  -0.35117231]\n",
      " [ 0.18259761  0.86257758 -0.36171871]\n",
      " [-0.18494502  0.62862214  0.96975408]]\n",
      "[[ 0.74905902]\n",
      " [-0.39263051]\n",
      " [-0.60168466]]\n",
      "[0 0] [0.43413242]\n",
      "[0 1] [0.22550872]\n",
      "[1 0] [0.43800374]\n",
      "[1 1] [0.22827013]\n",
      "epochs: 0\n",
      "epochs: 10000\n",
      "epochs: 20000\n",
      "epochs: 30000\n",
      "epochs: 40000\n",
      "epochs: 50000\n",
      "epochs: 60000\n",
      "epochs: 70000\n",
      "epochs: 80000\n",
      "epochs: 90000\n",
      "epochs: 100000\n",
      "epochs: 110000\n",
      "epochs: 120000\n",
      "epochs: 130000\n",
      "epochs: 140000\n",
      "epochs: 150000\n",
      "epochs: 160000\n",
      "epochs: 170000\n",
      "epochs: 180000\n",
      "epochs: 190000\n",
      "epochs: 200000\n",
      "epochs: 210000\n",
      "epochs: 220000\n",
      "epochs: 230000\n",
      "epochs: 240000\n",
      "epochs: 250000\n",
      "epochs: 260000\n",
      "epochs: 270000\n",
      "epochs: 280000\n",
      "epochs: 290000\n",
      "epochs: 300000\n",
      "epochs: 310000\n",
      "epochs: 320000\n",
      "epochs: 330000\n",
      "epochs: 340000\n",
      "epochs: 350000\n",
      "epochs: 360000\n",
      "epochs: 370000\n",
      "epochs: 380000\n",
      "epochs: 390000\n",
      "epochs: 400000\n",
      "epochs: 410000\n",
      "epochs: 420000\n",
      "epochs: 430000\n",
      "epochs: 440000\n",
      "epochs: 450000\n",
      "epochs: 460000\n",
      "epochs: 470000\n",
      "epochs: 480000\n",
      "epochs: 490000\n",
      "epochs: 500000\n",
      "epochs: 510000\n",
      "epochs: 520000\n",
      "epochs: 530000\n",
      "epochs: 540000\n",
      "epochs: 550000\n",
      "epochs: 560000\n",
      "epochs: 570000\n",
      "epochs: 580000\n",
      "epochs: 590000\n",
      "epochs: 600000\n",
      "epochs: 610000\n",
      "epochs: 620000\n",
      "epochs: 630000\n",
      "epochs: 640000\n",
      "epochs: 650000\n",
      "epochs: 660000\n",
      "epochs: 670000\n",
      "epochs: 680000\n",
      "epochs: 690000\n",
      "epochs: 700000\n",
      "epochs: 710000\n",
      "epochs: 720000\n",
      "epochs: 730000\n",
      "epochs: 740000\n",
      "epochs: 750000\n",
      "epochs: 760000\n",
      "epochs: 770000\n",
      "epochs: 780000\n",
      "epochs: 790000\n",
      "epochs: 800000\n",
      "epochs: 810000\n",
      "epochs: 820000\n",
      "epochs: 830000\n",
      "epochs: 840000\n",
      "epochs: 850000\n",
      "epochs: 860000\n",
      "epochs: 870000\n",
      "epochs: 880000\n",
      "epochs: 890000\n",
      "epochs: 900000\n",
      "epochs: 910000\n",
      "epochs: 920000\n",
      "epochs: 930000\n",
      "epochs: 940000\n",
      "epochs: 950000\n",
      "epochs: 960000\n",
      "epochs: 970000\n",
      "epochs: 980000\n",
      "epochs: 990000\n",
      "[0 0] [0.49859985]\n",
      "[0 1] [0.49860546]\n",
      "[1 0] [0.49952474]\n",
      "[1 1] [0.49953034]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        self.activation_linear = linear\n",
    "        self.activation_linear_prime = linear_prime\n",
    "        self.activation_sigmoid = sigmoid\n",
    "        self.activation_sigmoid_prime = sigmoid_prime\n",
    "        \n",
    "        # Set weights\n",
    "        self.weights = []\n",
    "        # layers = [2,2,1]\n",
    "        # range of weight values (-1,1)\n",
    "        # input and hidden layers - random((2+1, 2+1)) : 3 x 3\n",
    "        self.moments = []\n",
    "        for i in range(1, len(layers) - 1):\n",
    "            r = 2*np.random.random((layers[i-1] + 1, layers[i] + 1)) -1\n",
    "            self.weights.append(r)\n",
    "            self.moments.append(np.zeros(r.shape))\n",
    "            print(r)\n",
    "        # output layer - random((2+1, 1)) : 3 x 1\n",
    "        r = 2*np.random.random( (layers[i] + 1, layers[i+1])) - 1\n",
    "        print(r)\n",
    "        self.weights.append(r)\n",
    "        self.moments.append(np.zeros(r.shape))\n",
    "\n",
    "    def fit(self, X, y, learning_rate=0.2, epochs=100000, gamma=0.1):\n",
    "        # Add column of ones to X\n",
    "        # This is to add the bias unit to the input layer\n",
    "        ones = np.atleast_2d(np.ones(X.shape[0]))\n",
    "        X = np.concatenate((ones.T, X), axis=1)\n",
    "        errors = []\n",
    "        \n",
    "        for k in range(epochs):\n",
    "            i = np.random.randint(X.shape[0])\n",
    "            a = [X[i]]\n",
    "            \n",
    "            for l in range(len(self.weights)-1):\n",
    "                    dot_value = np.dot(a[l], self.weights[l])\n",
    "                    activation = self.activation_linear(dot_value)\n",
    "                    a.append(activation)\n",
    "            a.append(self.activation_sigmoid(np.dot(a[-1], self.weights[-1])))\n",
    "            # output layer\n",
    "            error = y[i] - a[-1]\n",
    "            errors.append(error**2)\n",
    "            deltas = [error * self.activation_sigmoid_prime(a[-1])]\n",
    "\n",
    "            # we need to begin at the second to last layer \n",
    "            # (a layer before the output layer)\n",
    "            for l in range(len(a) - 2, 0, -1):\n",
    "                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_linear_prime(a[l]))\n",
    "\n",
    "            # reverse\n",
    "            # [level3(output)->level2(hidden)]  => [level2(hidden)->level3(output)]\n",
    "            deltas.reverse()\n",
    "\n",
    "            # backpropagation\n",
    "            # 1. Multiply its output delta and input activation \n",
    "            #    to get the gradient of the weight.\n",
    "            # 2. Subtract a ratio (percentage) of the gradient from the weight.\n",
    "            for i in range(len(self.weights)):\n",
    "                layer = np.atleast_2d(a[i])\n",
    "                delta = np.atleast_2d(deltas[i])\n",
    "                prev_weight = np.copy(self.weights[i])\n",
    "                self.weights[i] += learning_rate * layer.T.dot(delta) + gamma*self.moments[i]\n",
    "                self.moments[i] = self.weights[i]-prev_weight\n",
    "\n",
    "            if k % 10000 == 0: \n",
    "                print('epochs:', k)\n",
    "                \n",
    "        return errors\n",
    "\n",
    "    def predict(self, x): \n",
    "    \n",
    "        a = np.concatenate((np.ones(1).T, np.array(x)))      \n",
    "\n",
    "        for l in range(len(self.weights)-1):\n",
    "            a = self.activation_linear(np.dot(a, self.weights[l]))\n",
    "        return self.activation_sigmoid(np.dot(a, self.weights[-1]))\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    nn = NeuralNetwork([2,2,1])\n",
    "    X = np.array([[0, 0],\n",
    "                  [0, 1],\n",
    "                  [1, 0],\n",
    "                  [1, 1]])\n",
    "    y = np.array([0, 1, 1, 0])\n",
    "#     X = np.array([[-1, -1],\n",
    "#                   [-1, 1],\n",
    "#                   [1, -1],\n",
    "#                   [1, 1]])\n",
    "#     y = np.array([0, 1, 1, 0])\n",
    "    epochs = 1000000\n",
    "    for e in X:\n",
    "        print(e,nn.predict(e))\n",
    "    errors = nn.fit(X, y, epochs=epochs, learning_rate=0.2, gamma=0.1)\n",
    "    for e in X:\n",
    "        print(e,nn.predict(e))\n",
    "        \n",
    "    plt.plot(np.arange(epochs), errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
